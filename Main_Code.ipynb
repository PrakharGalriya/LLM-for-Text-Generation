{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4X8dTqKSTSAE",
        "outputId": "7df57058-21e7-4585-99c7-3b5dda3d1a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.26.0->tiktoken) (2025.1.31)\n",
            "Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/1.2 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tiktoken\n",
            "Successfully installed tiktoken-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing libraries.\n",
        "import os\n",
        "from importlib.metadata import version\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "import tiktoken\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ],
      "metadata": {
        "id": "N9hFoPVFqnNj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2749e54a-697e-4125-e1b2-7c24ef325c2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.6.0+cu124\n",
            "tiktoken version: 0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this dictionary defines the architecture and training parameters for a 124 million parameter GPT model.\n",
        "#total number of trainable parameters are - 124 million.\n",
        "\n",
        "GPT_CONFIG_124M = {\n",
        "    #the number of unique tokens that the model can recognize and generate.\n",
        "    \"vocab_size\": 50257,\n",
        "\n",
        "    #the maximum number of tokens the model can process in a single forward pass.\n",
        "    \"context_length\": 1024,\n",
        "\n",
        "    #the size of the vector space used to represent each token.\n",
        "    \"emb_dim\": 768,\n",
        "\n",
        "    #the number of attention heads in each transformer layer.\n",
        "    \"n_heads\": 12,\n",
        "\n",
        "    #the number of transformer layers stacked on top of each other.\n",
        "    \"n_layers\": 12,\n",
        "\n",
        "    #the probability of randomly disabling neurons during training.\n",
        "    \"drop_rate\": 0.1,\n",
        "\n",
        "    #indicates whether bias terms are included in the query, key, and value projections of the attention mechanism.\n",
        "    \"qkv_bias\": False\n",
        "}"
      ],
      "metadata": {
        "id": "jmabrOIY1FRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib.request\n",
        "\n",
        "file_path_1 = \"text_data_1.txt\"\n",
        "url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"\n",
        "\n",
        "if not os.path.exists(file_path_1):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        text_data_1 = response.read().decode('utf-8')\n",
        "    with open(file_path_1, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data_1)\n",
        "else:\n",
        "    with open(file_path_1, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data_1 = file.read()\n"
      ],
      "metadata": {
        "id": "a0gDWLDUd_xx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_path_2 = \"text_data_2.txt\"\n",
        "url = \"https://www.gutenberg.org/cache/epub/1400/pg1400.txt\"\n",
        "\n",
        "if not os.path.exists(file_path_2):\n",
        "    with urllib.request.urlopen(url) as response:\n",
        "        text_data_2 = response.read().decode('utf-8')\n",
        "    with open(file_path_2, \"w\", encoding=\"utf-8\") as file:\n",
        "        file.write(text_data_2)\n",
        "else:\n",
        "    with open(file_path_2, \"r\", encoding=\"utf-8\") as file:\n",
        "        text_data_2 = file.read()"
      ],
      "metadata": {
        "id": "rGWHEQMVeDFd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = text_data_1 + text_data_2\n",
        "assert(len(dataset) == len(text_data_1) + len(text_data_2))"
      ],
      "metadata": {
        "id": "zFWcFLbVeF6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"final_dataset.txt\", \"w\", encoding = \"utf-8\") as file_1:\n",
        "    file_1.write(dataset)"
      ],
      "metadata": {
        "id": "aostcDq5ecxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"final_dataset.txt\", \"r\", encoding = \"utf-8\") as raw_text:\n",
        "  raw_text = raw_text.read()"
      ],
      "metadata": {
        "id": "HUh3logseIYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6fXx4_URyQl",
        "outputId": "99b5e7b4-4756-410a-e156-955bc9b02cde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch version: 2.6.0+cu124\n",
            "tiktoken version: 0.9.0\n"
          ]
        }
      ],
      "source": [
        "from importlib.metadata import version\n",
        "import tiktoken\n",
        "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "print(\"torch version:\", version(\"torch\"))\n",
        "print(\"tiktoken version:\", version(\"tiktoken\"))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_characters = len(raw_text)\n",
        "total_tokens = len(tokenizer.encode(raw_text))\n",
        "print(\"Characters:\", total_characters)\n",
        "print(\"Tokens:\", total_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ylT2F2S0qr1",
        "outputId": "56d0c2ac-f890-4a07-dbce-1d06bbbb7a57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Characters: 1762018\n",
            "Tokens: 480074\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_ratio = 0.90\n",
        "split_idx = int(train_ratio * len(raw_text))\n",
        "train_data = raw_text[:split_idx]\n",
        "val_data = raw_text[split_idx:]"
      ],
      "metadata": {
        "id": "j402mkJg05D3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, emb_dim):\n",
        "        super().__init__()\n",
        "        self.eps = 1e-5\n",
        "        self.scale = nn.Parameter(torch.ones(emb_dim))\n",
        "        self.shift = nn.Parameter(torch.zeros(emb_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "        norm_x = (x - mean) / torch.sqrt(var + self.eps)\n",
        "        return self.scale * norm_x + self.shift"
      ],
      "metadata": {
        "id": "RZULpPOg0Vw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return 0.5 * x * (1 + torch.tanh(\n",
        "            torch.sqrt(torch.tensor(2.0 / torch.pi)) *\n",
        "            (x + 0.044715 * torch.pow(x, 3))\n",
        "        ))"
      ],
      "metadata": {
        "id": "_FuSyqtuaqlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(cfg[\"emb_dim\"], 4 * cfg[\"emb_dim\"]),\n",
        "            GELU(),\n",
        "            nn.Linear(4 * cfg[\"emb_dim\"], cfg[\"emb_dim\"]),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)"
      ],
      "metadata": {
        "id": "fEFgnP1Ja0ZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_in, d_out, context_length, dropout, num_heads, qkv_bias=False):\n",
        "        super().__init__()\n",
        "        assert(d_out % num_heads == 0)\n",
        "        self.d_out = d_out\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.head_dim = d_out // num_heads  # Reduce the projection dim to match desired output dim\n",
        "\n",
        "        self.W_query = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_key = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.W_value = nn.Linear(d_in, d_out, bias=qkv_bias)\n",
        "        self.out_proj = nn.Linear(d_out, d_out)  # Linear layer to combine head outputs\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.register_buffer('mask', torch.triu(torch.ones(context_length, context_length), diagonal=1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, num_tokens, d_in = x.shape\n",
        "\n",
        "        keys = self.W_key(x)  # Shape: (b, num_tokens, d_out)\n",
        "        queries = self.W_query(x)\n",
        "        values = self.W_value(x)\n",
        "\n",
        "        # We implicitly split the matrix by adding a `num_heads` dimension\n",
        "        # Unroll last dim: (b, num_tokens, d_out) -> (b, num_tokens, num_heads, head_dim)\n",
        "        keys = keys.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        values = values.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "        queries = queries.view(b, num_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose: (b, num_tokens, num_heads, head_dim) -> (b, num_heads, num_tokens, head_dim)\n",
        "        keys = keys.transpose(1, 2)\n",
        "        queries = queries.transpose(1, 2)\n",
        "        values = values.transpose(1, 2)\n",
        "\n",
        "        # Compute scaled dot-product attention (aka self-attention) with a causal mask\n",
        "        attn_scores = queries @ keys.transpose(2, 3)  # Dot product for each head\n",
        "\n",
        "        # Original mask truncated to the number of tokens and converted to boolean\n",
        "        mask_bool = self.mask.bool()[:num_tokens, :num_tokens]\n",
        "\n",
        "        # Use the mask to fill attention scores\n",
        "        attn_scores.masked_fill_(mask_bool, -torch.inf)\n",
        "\n",
        "        attn_weights = torch.softmax(attn_scores / keys.shape[-1]**0.5, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Shape: (b, num_tokens, num_heads, head_dim)\n",
        "        context_vec = (attn_weights @ values).transpose(1, 2)\n",
        "\n",
        "        # Combine heads, where self.d_out = self.num_heads * self.head_dim\n",
        "        context_vec = context_vec.contiguous().view(\n",
        "            b, num_tokens, self.d_out\n",
        "        )\n",
        "        context_vec = self.out_proj(context_vec)  # optional projection\n",
        "\n",
        "        return context_vec"
      ],
      "metadata": {
        "id": "S3zJ7c3RpPMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.att = MultiHeadAttention(\n",
        "            d_in=cfg[\"emb_dim\"],\n",
        "            d_out=cfg[\"emb_dim\"],\n",
        "            context_length=cfg[\"context_length\"],\n",
        "            num_heads=cfg[\"n_heads\"],\n",
        "            dropout=cfg[\"drop_rate\"],\n",
        "            qkv_bias=cfg[\"qkv_bias\"])\n",
        "        self.ff = FeedForward(cfg)\n",
        "        self.norm1 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.norm2 = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.drop_resid = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Shortcut connection for attention block\n",
        "        shortcut = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.att(x)   # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        # Shortcut connection for feed-forward block\n",
        "        shortcut = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff(x)\n",
        "        x = self.drop_resid(x)\n",
        "        x = x + shortcut  # Add the original input back\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "Ao7jCC0na2jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GPTModel(nn.Module):\n",
        "    def __init__(self, cfg):\n",
        "        super().__init__()\n",
        "        self.tok_emb = nn.Embedding(cfg[\"vocab_size\"], cfg[\"emb_dim\"])\n",
        "        self.pos_emb = nn.Embedding(cfg[\"context_length\"], cfg[\"emb_dim\"])\n",
        "        self.drop_emb = nn.Dropout(cfg[\"drop_rate\"])\n",
        "\n",
        "        self.trf_blocks = nn.Sequential(\n",
        "            *[TransformerBlock(cfg) for _ in range(cfg[\"n_layers\"])])\n",
        "\n",
        "        self.final_norm = LayerNorm(cfg[\"emb_dim\"])\n",
        "        self.out_head = nn.Linear(cfg[\"emb_dim\"], cfg[\"vocab_size\"], bias=False)\n",
        "\n",
        "    def forward(self, in_idx):\n",
        "        batch_size, seq_len = in_idx.shape\n",
        "        tok_embeds = self.tok_emb(in_idx)\n",
        "        pos_embeds = self.pos_emb(torch.arange(seq_len, device=in_idx.device))\n",
        "        x = tok_embeds + pos_embeds  # Shape [batch_size, num_tokens, emb_size]\n",
        "        x = self.drop_emb(x)\n",
        "        x = self.trf_blocks(x)\n",
        "        x = self.final_norm(x)\n",
        "        logits = self.out_head(x)\n",
        "        return logits"
      ],
      "metadata": {
        "id": "0cm_IxITa7HK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model, idx, max_new_tokens, context_size, device):\n",
        "    idx = idx.to(device)\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "\n",
        "        # Crop current context if it exceeds the supported context size\n",
        "        # E.g., if LLM supports only 5 tokens, and the context size is 10\n",
        "        # then only the last 5 tokens are used as context\n",
        "        idx_cond = idx[:, -context_size:]\n",
        "\n",
        "        # Get the predictions\n",
        "        with torch.no_grad():\n",
        "            logits = model(idx_cond)\n",
        "\n",
        "        # Focus only on the last time step\n",
        "        # (batch, n_token, vocab_size) becomes (batch, vocab_size)\n",
        "        logits = logits[:, -1, :]\n",
        "\n",
        "        # Get the idx of the vocab entry with the highest logits value\n",
        "        idx_next = torch.argmax(logits, dim=-1, keepdim=True)  # (batch, 1)\n",
        "\n",
        "        # Append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1)  # (batch, n_tokens+1)\n",
        "\n",
        "    return idx"
      ],
      "metadata": {
        "id": "5unycCBca-qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#helper function that takes a text string and tokenizer, then returns a properly formatted tensor.\n",
        "def text_to_token_ids(text, tokenizer):\n",
        "\n",
        "    #encodes the text into token IDs, allows the special end-of-text token\n",
        "    encoded = tokenizer.encode(text, allowed_special = {'<|endoftext|>'})\n",
        "\n",
        "    #converts to a tensor and adds the batch dimension\n",
        "    encoded_tensor = torch.tensor(encoded).unsqueeze(0)\n",
        "\n",
        "    #returns the ready-to-use tensor\n",
        "    return encoded_tensor\n",
        "\n",
        "#function that converts generated token IDs back to human-readable text.\n",
        "def token_ids_to_text(token_ids, tokenizer):\n",
        "\n",
        "    #removes the batch dimension with 'squeeze(0)'\n",
        "    flat = token_ids.squeeze(0)\n",
        "\n",
        "    #decodes the token IDs to text and converts the tensor to a python list with tolist()\n",
        "    return tokenizer.decode(flat.tolist())\n"
      ],
      "metadata": {
        "id": "NRhpimkbbIgc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#we create a class which inherits from pytorch's 'Dataset' class, which is part of the data loading infrastructure in pytorch.\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "class GPTDatasetV1(Dataset):\n",
        "\n",
        "     #txt: the raw text to train on.\n",
        "     #tokenizer: the tokenizer to convert text to token IDs.\n",
        "     #max_length: the maximum sequence length for each training example.\n",
        "     #stride: how much to shift the window when creating the next training example.\n",
        "     def __init__(self, txt, tokenizer, max_length, stride):\n",
        "\n",
        "         #these lists will store the input sequences and their corresponding target sequences.\n",
        "         self.input_ids = []\n",
        "         self.target_ids = []\n",
        "\n",
        "         #encodes the entire text into token IDs, allowing the special end-of-text token to be included.\n",
        "         token_ids = tokenizer.encode(txt, allowed_special = {\"<|endoftext|>\"})\n",
        "         assert len(token_ids) > max_length, \"Number of tokenized inputs must at least be equal to max_length+1\"\n",
        "\n",
        "         #this loop iterates through the token IDs, jumping stride positions each time. this creates overlapping chunks if stride < max_length, which is a common approach to efficiently use all the data.\n",
        "         for i in range(0, len(token_ids) - max_length, stride):\n",
        "\n",
        "             #input_chunk is a sequence of max_length tokens starting at position i.\n",
        "             input_chunk = token_ids[i:i + max_length]\n",
        "\n",
        "             #target_chunk is a sequence of the same length but shifted one position forward.\n",
        "             target_chunk = token_ids[i + 1: i + max_length + 1]\n",
        "\n",
        "             #each chunk is converted to a PyTorch tensor and stored in the appropriate list.\n",
        "             self.input_ids.append(torch.tensor(input_chunk))\n",
        "             self.target_ids.append(torch.tensor(target_chunk))\n",
        "\n",
        "     #returns the number of examples in the dataset.\n",
        "     def __len__(self):\n",
        "         return len(self.input_ids)\n",
        "\n",
        "     #returns a specific example from the dataset given its index.\n",
        "     def __getitem__(self, idx):\n",
        "         return self.input_ids[idx], self.target_ids[idx]"
      ],
      "metadata": {
        "id": "Y0ZmPGeIO_Qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataloader_v1(txt, batch_size=4, max_length=256,\n",
        "                         stride=128, shuffle=True, drop_last=True,\n",
        "                         num_workers=0):\n",
        "\n",
        "    tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
        "\n",
        "    dataset = GPTDatasetV1(txt, tokenizer, max_length, stride)\n",
        "\n",
        "    dataloader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=shuffle,\n",
        "        drop_last=drop_last,\n",
        "        num_workers=num_workers\n",
        " )\n",
        "\n",
        "    return dataloader"
      ],
      "metadata": {
        "id": "SNviWcohlmEC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = create_dataloader_v1(\n",
        "     train_data,\n",
        "     batch_size=2,\n",
        "     max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "     stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "     drop_last=True,\n",
        "     shuffle=True,\n",
        "     num_workers=0\n",
        ")\n",
        "\n",
        "\n",
        "val_loader = create_dataloader_v1(\n",
        "     val_data,\n",
        "     batch_size=2,\n",
        "     max_length=GPT_CONFIG_124M[\"context_length\"],\n",
        "     stride=GPT_CONFIG_124M[\"context_length\"],\n",
        "     drop_last=False,\n",
        "     shuffle=False,\n",
        "     num_workers=0\n",
        ")"
      ],
      "metadata": {
        "id": "r9SLRGYXq2VF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_batch(input_batch, target_batch, model, device):\n",
        "     input_batch, target_batch = input_batch.to(device), target_batch.to(device)\n",
        "     logits = model(input_batch)\n",
        "     loss = torch.nn.functional.cross_entropy(\n",
        "         logits.flatten(0, 1), target_batch.flatten()\n",
        "     )\n",
        "     return loss"
      ],
      "metadata": {
        "id": "N6nkpVu5G_kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
        "     total_loss = 0\n",
        "     if len(data_loader) == 0:\n",
        "         return float(\"nan\")\n",
        "     elif num_batches is None:\n",
        "         num_batches = len(data_loader)\n",
        "     else:\n",
        "         num_batches = min(num_batches, len(data_loader))\n",
        "     for i, (input_batch, target_batch) in enumerate(data_loader):\n",
        "         if i < num_batches:\n",
        "             loss = calc_loss_batch(\n",
        "                 input_batch, target_batch, model, device\n",
        "             )\n",
        "             total_loss += loss.item()\n",
        "         else:\n",
        "             break\n",
        "     return total_loss / num_batches"
      ],
      "metadata": {
        "id": "Sfj02mpgGvsm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "with torch.no_grad():\n",
        "    train_loss = calc_loss_loader(train_loader, model, device)\n",
        "    val_loss = calc_loss_loader(val_loader, model, device)\n",
        "print(\"Training loss:\", train_loss)\n",
        "print(\"Validation loss:\", val_loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvhHy4YpIF2A",
        "outputId": "fcd60d71-3a39-49a7-a79c-4b756c056c85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training loss: 10.997751081557501\n",
            "Validation loss: 10.990206552588422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model_simple(model, train_loader, val_loader, optimizer, device, num_epochs,\n",
        "                       eval_freq, eval_iter, start_context, tokenizer):\n",
        "    # Initialize lists to track losses and tokens seen\n",
        "    train_losses, val_losses, track_tokens_seen = [], [], []\n",
        "    tokens_seen, global_step = 0, -1\n",
        "\n",
        "    # Main training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()  # Set model to training mode\n",
        "\n",
        "        for input_batch, target_batch in train_loader:\n",
        "            optimizer.zero_grad() # Reset loss gradients from previous batch iteration\n",
        "            loss = calc_loss_batch(input_batch, target_batch, model, device)\n",
        "            loss.backward() # Calculate loss gradients\n",
        "            optimizer.step() # Update model weights using loss gradients\n",
        "            tokens_seen += input_batch.numel()\n",
        "            global_step += 1\n",
        "\n",
        "            # Optional evaluation step\n",
        "            if global_step % eval_freq == 0:\n",
        "                train_loss, val_loss = evaluate_model(\n",
        "                    model, train_loader, val_loader, device, eval_iter)\n",
        "                train_losses.append(train_loss)\n",
        "                val_losses.append(val_loss)\n",
        "                track_tokens_seen.append(tokens_seen)\n",
        "                print(f\"Ep {epoch+1} (Step {global_step:06d}): \"\n",
        "                      f\"Train loss {train_loss:.3f}, Val loss {val_loss:.3f}\")\n",
        "\n",
        "        # Print a sample text after each epoch\n",
        "        generate_and_print_sample(\n",
        "            model, tokenizer, device, start_context\n",
        "        )\n",
        "\n",
        "    return train_losses, val_losses, track_tokens_seen\n",
        "\n",
        "\n",
        "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        train_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
        "        val_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
        "    model.train()\n",
        "    return train_loss, val_loss\n",
        "\n",
        "\n",
        "def generate_and_print_sample(model, tokenizer, device, start_context):\n",
        "    model.eval()\n",
        "    context_size = model.pos_emb.weight.shape[0]\n",
        "    encoded = text_to_token_ids(start_context, tokenizer).to(device)\n",
        "    with torch.no_grad():\n",
        "        token_ids = generate_text(\n",
        "            model=model, idx=encoded,\n",
        "            max_new_tokens=50, context_size=context_size, device=device\n",
        "        )\n",
        "    decoded_text = token_ids_to_text(token_ids, tokenizer)\n",
        "    print(decoded_text.replace(\"\\n\", \" \"))  # Compact print format\n",
        "    model.train()"
      ],
      "metadata": {
        "id": "hRfhP3HHCubB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.to(device)\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=0.00005, weight_decay=0.02\n",
        ")\n",
        "num_epochs = 5\n",
        "\n",
        "train_losses, val_losses, tokens_seen = train_model_simple(\n",
        "    model, train_loader, val_loader, optimizer, device,\n",
        "    num_epochs=num_epochs, eval_freq=10, eval_iter=5,\n",
        "    start_context=\"Every effort moves you\", tokenizer=tokenizer\n",
        ")"
      ],
      "metadata": {
        "id": "EPtOo7XeQtgb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dfdba7a-8bc4-434d-8755-72ee868853b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ep 1 (Step 000000): Train loss 10.711, Val loss 10.712\n",
            "Ep 1 (Step 000010): Train loss 9.009, Val loss 9.053\n",
            "Ep 1 (Step 000020): Train loss 8.447, Val loss 8.469\n",
            "Ep 1 (Step 000030): Train loss 8.127, Val loss 8.020\n",
            "Ep 1 (Step 000040): Train loss 6.900, Val loss 7.566\n",
            "Ep 1 (Step 000050): Train loss 7.197, Val loss 7.143\n",
            "Ep 1 (Step 000060): Train loss 6.355, Val loss 6.815\n",
            "Ep 1 (Step 000070): Train loss 6.486, Val loss 6.569\n",
            "Ep 1 (Step 000080): Train loss 6.215, Val loss 6.386\n",
            "Every effort moves you, and                                                \n",
            "Ep 2 (Step 000090): Train loss 6.358, Val loss 6.235\n",
            "Ep 2 (Step 000100): Train loss 6.054, Val loss 6.124\n",
            "Ep 2 (Step 000110): Train loss 5.553, Val loss 6.034\n",
            "Ep 2 (Step 000120): Train loss 5.479, Val loss 5.963\n",
            "Ep 2 (Step 000130): Train loss 5.561, Val loss 5.900\n",
            "Ep 2 (Step 000140): Train loss 5.504, Val loss 5.836\n",
            "Ep 2 (Step 000150): Train loss 5.391, Val loss 5.783\n",
            "Ep 2 (Step 000160): Train loss 5.622, Val loss 5.740\n",
            "Ep 2 (Step 000170): Train loss 5.292, Val loss 5.704\n",
            "Every effort moves you.  ” ” “I, and “I.“I “I a “I, and ” ” “I, and ” �\n",
            "Ep 3 (Step 000180): Train loss 5.471, Val loss 5.671\n",
            "Ep 3 (Step 000190): Train loss 4.632, Val loss 5.632\n",
            "Ep 3 (Step 000200): Train loss 5.516, Val loss 5.600\n",
            "Ep 3 (Step 000210): Train loss 5.413, Val loss 5.572\n",
            "Ep 3 (Step 000220): Train loss 5.439, Val loss 5.531\n",
            "Ep 3 (Step 000230): Train loss 5.364, Val loss 5.506\n",
            "Ep 3 (Step 000240): Train loss 5.429, Val loss 5.484\n",
            "Ep 3 (Step 000250): Train loss 5.052, Val loss 5.453\n",
            "Every effort moves you  “I am not be “I am“I am not be “I have been “I am“I am sure,“I am.“I am“I am \n",
            "Ep 4 (Step 000260): Train loss 5.217, Val loss 5.421\n",
            "Ep 4 (Step 000270): Train loss 4.844, Val loss 5.402\n",
            "Ep 4 (Step 000280): Train loss 5.162, Val loss 5.384\n",
            "Ep 4 (Step 000290): Train loss 5.146, Val loss 5.364\n",
            "Ep 4 (Step 000300): Train loss 5.229, Val loss 5.346\n",
            "Ep 4 (Step 000310): Train loss 5.047, Val loss 5.321\n",
            "Ep 4 (Step 000320): Train loss 4.604, Val loss 5.301\n",
            "Ep 4 (Step 000330): Train loss 5.055, Val loss 5.284\n",
            "Ep 4 (Step 000340): Train loss 4.948, Val loss 5.271\n",
            "Every effort moves you ” “I am sure.“I am sure you have been ” “I am sure” “I am sure,“I am sure“I am sure” �\n",
            "Ep 5 (Step 000350): Train loss 4.965, Val loss 5.261\n",
            "Ep 5 (Step 000360): Train loss 4.922, Val loss 5.238\n",
            "Ep 5 (Step 000370): Train loss 5.013, Val loss 5.240\n",
            "Ep 5 (Step 000380): Train loss 4.900, Val loss 5.220\n",
            "Ep 5 (Step 000390): Train loss 4.654, Val loss 5.210\n",
            "Ep 5 (Step 000400): Train loss 4.923, Val loss 5.192\n",
            "Ep 5 (Step 000410): Train loss 5.031, Val loss 5.172\n",
            "Ep 5 (Step 000420): Train loss 4.945, Val loss 5.154\n",
            "Every effort moves you “I am not be so much.” “I am not be “I have been “I am not to be so much to be a ” ” “I am sure\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import MaxNLocator\n",
        "import torch\n",
        "\n",
        "def plot_losses(epochs_seen, tokens_seen, train_losses, val_losses):\n",
        "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
        "    ax1.plot(epochs_seen, train_losses, label=\"Training loss\")\n",
        "    ax1.plot(epochs_seen, val_losses, linestyle=\"-.\", label=\"Validation loss\")\n",
        "\n",
        "    ax1.set_xlabel(\"Epochs\")\n",
        "    ax1.set_ylabel(\"Loss\")\n",
        "    ax1.legend(loc=\"upper right\")\n",
        "    ax1.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    ax2 = ax1.twiny()\n",
        "    ax2.plot(tokens_seen, train_losses, alpha=0)\n",
        "    ax2.set_xlabel(\"Tokens seen\")\n",
        "\n",
        "    fig.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
        "plot_losses(epochs_tensor, tokens_seen, train_losses, val_losses)"
      ],
      "metadata": {
        "id": "ru5U0PaybKOf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bcefcd4-a555-45df-82b5-7155e785e357"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x300 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAekAAAEiCAYAAADd4SrgAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAXL9JREFUeJzt3Xl8TNf7wPHPTPZ9I5ssghAisUWU0I3alaJUtUW12qL4qmp926rqr9VFW1Wq1X5LF63qolW1FLXVGkvsYpcgi8i+JzPn98cwkQoSkswknvfrdV+Zuffce5+5Ic+ce849R6OUUgghhBDC7GhNHYAQQgghyiZJWgghhDBTkqSFEEIIMyVJWgghhDBTkqSFEEIIMyVJWgghhDBTkqSFEEIIMyVJWgghhDBTkqSFEEIIMyVJWoga7syZM2g0GmJiYkwdihCikkmSFsIMaDSaGy7Tpk0zdYhCCBOwNHUAQghISEgwvv7xxx+ZOnUqsbGxxnWOjo6mCEsIYWJSkxbCDHh7exsXFxcXNBqN8b2npycffvghfn5+2NjY0LJlS1atWnXdY+l0Op588klCQkKIi4sD4Pfff6d169bY2trSoEED3njjDYqLi437aDQavvzySx566CHs7e0JDg5m2bJlxu1paWkMHTqUunXrYmdnR3BwMAsWLLhuDD///DNhYWHY2dnh4eFBly5dyMnJMW7/8ssvadq0Kba2toSEhPDpp5+W2j8+Pp5Bgwbh6uqKu7s7ffv25cyZM8btw4cPp1+/fsycORMfHx88PDwYM2YMRUVF5b7mQtQISghhVhYsWKBcXFyM7z/88EPl7OysfvjhB3X06FE1efJkZWVlpY4dO6aUUur06dMKUHv37lX5+fnqoYceUq1atVLJyclKKaU2bdqknJ2d1cKFC9XJkyfVX3/9perXr6+mTZtmPAeg/Pz81Pfff6+OHz+uxo0bpxwdHdWlS5eUUkqNGTNGtWzZUkVHR6vTp0+rNWvWqGXLlpUZ/4ULF5SlpaX68MMP1enTp9X+/fvV3LlzVVZWllJKqe+++075+PioX375RZ06dUr98ssvyt3dXS1cuFAppVRhYaFq2rSpevLJJ9X+/fvV4cOH1aOPPqqaNGmiCgoKlFJKDRs2TDk7O6tnn31WHTlyRP3xxx/K3t5ezZ8/v3J/GUKYmCRpIczMv5O0r6+veuutt0qVadu2rRo9erRSqiRJb968WXXu3Fl17NhRpaenG8t27txZvf3226X2//bbb5WPj4/xPaBeffVV4/vs7GwFqJUrVyqllOrTp48aMWJEueLfvXu3AtSZM2fK3N6wYUP1/fffl1r35ptvqvbt2xtja9KkidLr9cbtBQUFys7OTq1evVopZUjSgYGBqri42Fjm4YcfVoMHDy5XjELUFNImLYQZy8zM5MKFC0RFRZVaHxUVxb59+0qtGzJkCH5+fvz999/Y2dkZ1+/bt48tW7bw1ltvGdfpdDry8/PJzc3F3t4egPDwcON2BwcHnJ2dSU5OBuC5555jwIAB7Nmzh65du9KvXz86dOhQZswtWrSgc+fOhIWF0a1bN7p27crAgQNxc3MjJyeHkydPMnLkSJ5++mnjPsXFxbi4uBjjPXHiBE5OTqWOm5+fz8mTJ43vQ0NDsbCwML738fHhwIEDN7iaQtQ8kqSFqCV69uzJd999x7Zt27j//vuN67Ozs3njjTfo37//NfvY2toaX1tZWZXaptFo0Ov1APTo0YOzZ8+yYsUK1qxZQ+fOnRkzZgwzZ8685pgWFhasWbOGrVu38tdff/HJJ5/wyiuvsGPHDuMXgi+++IJ27dpds9+VeNu0acOiRYuuOXbdunXLFa8QtYUkaSHMmLOzM76+vmzZsoV77rnHuH7Lli1ERkaWKvvcc8/RvHlzHnzwQf78809j+datWxMbG0ujRo1uK5a6desybNgwhg0bRqdOnXjxxRfLTNJgSJhRUVFERUUxdepUAgMDWbp0KRMnTsTX15dTp04xdOjQMvdt3bo1P/74I56enjg7O99WzELUdJKkhTBzL774Iq+//joNGzakZcuWLFiwgJiYmDJrms8//zw6nY7evXuzcuVKOnbsyNSpU+nduzcBAQEMHDgQrVbLvn37OHjwIP/3f/9XrhimTp1KmzZtCA0NpaCggOXLl9O0adMyy+7YsYN169bRtWtXPD092bFjBxcvXjSWf+ONNxg3bhwuLi50796dgoICdu3aRVpaGhMnTmTo0KG8//779O3bl+nTp+Pn58fZs2f59ddfmTx5Mn5+frd+MYWoYSRJC2Hmxo0bR0ZGBi+88ALJyck0a9aMZcuWERwcXGb5CRMmoNfr6dmzJ6tWraJbt24sX76c6dOn8+6772JlZUVISAhPPfVUuWOwtrZmypQpnDlzBjs7Ozp16sTixYvLLOvs7MymTZuYNWsWmZmZBAYG8sEHH9CjRw8AnnrqKezt7Xn//fd58cUXcXBwICwsjAkTJgBgb2/Ppk2beOmll+jfvz9ZWVnUq1ePzp07S81a3HE0Sill6iCEEEIIcS0ZzEQIIYQwU5KkhRBCCDMlSVoIIYQwU5KkhRBCCDMlSVoIIYQwU5KkhRBCCDMlSbqc5s6dS/369bG1taVdu3bs3LnT1CFVuxkzZtC2bVucnJzw9PSkX79+peY8BsP4ymPGjMHDwwNHR0cGDBhAUlJSqTJxcXH06tULe3t7PD09efHFF0tNmwiwYcMGWrdujY2NDY0aNWLhwoXXxHOz30l5YjF377zzDhqNxvgMMcg1riznz5/nsccew8PDAzs7O8LCwti1a5dxu1KKqVOn4uPjg52dHV26dOH48eOljpGamsrQoUNxdnbG1dWVkSNHkp2dXarM/v376dSpE7a2tvj7+/Pee+9dE8tPP/1ESEgItra2hIWFsWLFilLbyxOLOdLpdLz22msEBQVhZ2dHw4YNefPNN7n6yV+5zjdhwsk9aozFixcra2tr9dVXX6lDhw6pp59+Wrm6uqqkpCRTh1atunXrphYsWKAOHjyoYmJiVM+ePVVAQIDKzs42lnn22WeVv7+/Wrdundq1a5e66667VIcOHYzbi4uLVfPmzVWXLl3U3r171YoVK1SdOnXUlClTjGVOnTql7O3t1cSJE9Xhw4fVJ598oiwsLNSqVauMZcrzO7lZLOZu586dqn79+io8PFyNHz/euF6u8e1LTU1VgYGBavjw4WrHjh3q1KlTavXq1erEiRPGMu+8845ycXFRv/32m9q3b5968MEHVVBQkMrLyzOW6d69u2rRooXavn272rx5s2rUqJEaMmSIcXtGRoby8vJSQ4cOVQcPHlQ//PCDsrOzU59//rmxzJYtW5SFhYV677331OHDh9Wrr76qrKys1IEDByoUizl66623lIeHh1q+fLk6ffq0+umnn5Sjo6P6+OOPjWXkOt+YJOlyiIyMVGPGjDG+1+l0ytfXV82YMcOEUZlecnKyAtTGjRuVUkqlp6crKysr9dNPPxnLHDlyRAFq27ZtSimlVqxYobRarUpMTDSWmTdvnnJ2djbOFTx58mQVGhpa6lyDBw9W3bp1M76/2e+kPLGYs6ysLBUcHKzWrFmj7rnnHmOSlmtcOV566SXVsWPH627X6/XK29tbvf/++8Z16enpysbGRv3www9KKaUOHz6sABUdHW0ss3LlSqXRaNT58+eVUkp9+umnys3NzXjdr5y7SZMmxveDBg1SvXr1KnX+du3aqWeeeabcsZirXr16qSeffLLUuv79+6uhQ4cqpeQ6l4fc7r6JwsJCdu/eTZcuXYzrtFotXbp0Ydu2bSaMzPQyMjIAcHd3B2D37t0UFRWVulYhISEEBAQYr9W2bdsICwvDy8vLWKZbt25kZmZy6NAhY5mrj3GlzJVjlOd3Up5YzNmYMWPo1avXNddBrnHlWLZsGRERETz88MN4enrSqlUrvvjiC+P206dPk5iYWOqzubi40K5du1LX2dXVlYiICGOZLl26oNVq2bFjh7HM3XffjbW1tbFMt27diI2NJS0tzVjmRr+L8sRirjp06MC6des4duwYYJiG9J9//jEOESvX+eZk7O6bSElJQafTlfqDB+Dl5cXRo0dNFJXp6fV6JkyYQFRUFM2bNwcgMTERa2trXF1dS5X18vIiMTHRWKasa3ll243KZGZmkpeXR1pa2k1/J+WJxVwtXryYPXv2EB0dfc02ucaV49SpU8ybN4+JEyfy3//+l+joaMaNG4e1tTXDhg0zxl/W57/6Gnp6epbabmlpibu7e6kyQUFB1xzjyjY3N7fr/i6uPsbNYjFXL7/8MpmZmYSEhGBhYYFOp+Ott94yzoAm1/nmJEmLWzJmzBgOHjzIP//8Y+pQapX4+HjGjx/PmjVrSs31LCqXXq8nIiKCt99+G4BWrVpx8OBBPvvsM4YNG2bi6GqPJUuWsGjRIr7//ntCQ0OJiYlhwoQJ+Pr6ynUuJ7ndfRN16tTBwsLimh6rSUlJeHt7mygq0xo7dizLly9n/fr1paYN9Pb2prCwkPT09FLlr75W3t7eZV7LK9tuVMbZ2Rk7O7ty/U7KE4s52r17N8nJybRu3RpLS0ssLS3ZuHEjs2fPxtLSEi8vL7nGlcDHx4dmzZqVWte0aVPi4uKAkut0s8+fnJxcantxcTGpqamV8ru4evvNYjFXL774Ii+//DKPPPIIYWFhPP744/znP/9hxowZgFzn8pAkfRPW1ta0adOGdevWGdfp9XrWrVtH+/btTRhZ9VNKMXbsWJYuXcrff/99ze2lNm3aYGVlVepaxcbGEhcXZ7xW7du358CBA6X+061ZswZnZ2fjH8327duXOsaVMleOUZ7fSXliMUedO3fmwIEDxMTEGJeIiAiGDh1qfC3X+PZFRUVd8/jgsWPHCAwMBCAoKAhvb+9Sny0zM5MdO3aUus7p6ens3r3bWObvv/9Gr9fTrl07Y5lNmzZRVFRkLLNmzRqaNGmCm5ubscyNfhflicVc5ebmotWWTjMWFhbo9XpArnO5mKzLWg2yePFiZWNjoxYuXKgOHz6sRo0apVxdXUv1nr0TPPfcc8rFxUVt2LBBJSQkGJfc3FxjmWeffVYFBASov//+W+3atUu1b99etW/f3rj9yuNBXbt2VTExMWrVqlWqbt26ZT4e9OKLL6ojR46ouXPnlvl40M1+JzeLpaa4une3UnKNK8POnTuVpaWleuutt9Tx48fVokWLlL29vfruu++MZd555x3l6uqqfv/9d7V//37Vt2/fMh8NatWqldqxY4f6559/VHBwcKlHg9LT05WXl5d6/PHH1cGDB9XixYuVvb39NY8GWVpaqpkzZ6ojR46o119/vcxHg24WizkaNmyYqlevnvERrF9//VXVqVNHTZ482VhGrvONSZIup08++UQFBAQoa2trFRkZqbZv327qkKodUOayYMECY5m8vDw1evRo5ebmpuzt7dVDDz2kEhISSh3nzJkzqkePHsrOzk7VqVNHvfDCC6qoqKhUmfXr16uWLVsqa2tr1aBBg1LnuOJmv5PyxFIT/DtJyzWuHH/88Ydq3ry5srGxUSEhIWr+/Pmltuv1evXaa68pLy8vZWNjozp37qxiY2NLlbl06ZIaMmSIcnR0VM7OzmrEiBEqKyurVJl9+/apjh07KhsbG1WvXj31zjvvXBPLkiVLVOPGjZW1tbUKDQ1Vf/75Z4VjMUeZmZlq/PjxKiAgQNna2qoGDRqoV155pdSjUnKdb0yj1FVDvwghhBDCbEibtBBCCGGmJEkLIYQQZkqStBBCCGGmJEkLIYQQZkqStBBCCGGmJEkLIYQQZkqSdDkVFBQwbdo0CgoKTB1KrSbXuerJNa56co2rx51wneU56XLKzMzExcWFjIwMnJ2dTR1OrSXXuerJNa56co2rx51wnaUmLYQQQpgpSdJCCCGEmar180kXFxezd+9evLy8rpmNpSKysrIAOH/+PJmZmZUVnvgXuc5VT65x1ZNrXD1q8nXW6/UkJSXRqlUrLC2vn4prfZt0dHQ0kZGRpg5DCCGEuMbOnTtp27btdbfX+pq0l5cXYLgQPj4+Jo5GCCGEgISEBCIjI4056npqfZK+covbx8cHPz8/E0cjhBBClLhZM6x0HBNCCCHMlCRpIYQQwkxJkhZCCCHMVK1vkxZCiIrQ6XQUFRWZOgxRw1lZWWFhYXHbx5EkXU5KKU6n5HA4IZNeYT5oNBpThySEqERKKRITE0lPTzd1KKKWcHV1xdvb+7byhSTpcirSKZ6c9Ssh6iQt3Ubi5x9g6pCEEJXoSoL29PTE3t5evoiLW6aUIjc3l+TkZIDbevxXknQ5WVtqmW87m8a64+w9EICf/0hThySEqCQ6nc6YoD08PEwdjqgF7OzsAEhOTsbT0/OWb31Lx7EKSHVpBkDRuT0mjkQIUZmutEHb29ubOBJRm1z593Q7fRwkSVeA8mkJgMOlg6YNRAhRJeQWt6hMlfHvSZJ0Bbg2Moyv6l9wHKXXmzgaIYQQtZ0k6QqoHxJBgbLEmRwunTtm6nCEEKLS1a9fn1mzZpW7/IYNG9BoNFXeK37hwoW4urpW6TnMkSTpCrCzs+OsZX0AEo9uM20wQog7mkajueEybdq0WzpudHQ0o0aNKnf5Dh06kJCQgIuLyy2dT9yY9O6uoBSnpjROP0F+3F5ghKnDEULcoRISEoyvf/zxR6ZOnUpsbKxxnaOjo/G1UgqdTnfDeYuvqFu3boXisLa2xtvbu0L7iPKTmnQF6bxbAGB/6YCJIxFC3Mm8vb2Ni4uLCxqNxvj+6NGjODk5sXLlStq0aYONjQ3//PMPJ0+epG/fvnh5eeHo6Ejbtm1Zu3ZtqeP++3a3RqPhyy+/5KGHHsLe3p7g4GCWLVtm3P7v291XbkuvXr2apk2b4ujoSPfu3Ut9qSguLmbcuHG4urri4eHBSy+9xLBhw+jXr1+FrsG8efNo2LAh1tbWNGnShG+//da4TSnFtGnTCAgIwMbGBl9fX8aNG2fc/umnnxIcHIytrS1eXl4MHDiwQueuLpKkK8ilgaHzmF/eMVDKxNEIIaqKUorcwuJqX1Ql/l15+eWXeeeddzhy5Ajh4eFkZ2fTs2dP1q1bx969e+nevTt9+vQhLi7uhsd54403GDRoEPv376dnz54MHTqU1NTU65bPzc1l5syZfPvtt2zatIm4uDgmTZpk3P7uu++yaNEiFixYwJYtW8jMzOS3336r0GdbunQp48eP54UXXuDgwYM888wzjBgxgvXr1wPwyy+/8NFHH/H5559z/PhxfvvtN8LCwgDYtWsX48aNY/r06cTGxrJq1SruvvvuCp2/usjt7goKbBpB4Z8WOGuyybhwApd6waYOSQhRBfKKdDSburraz3t4ejfsrSvnT/P06dN54IEHjO/d3d1p0aKF8f2bb77J0qVLWbZsGWPHjr3ucYYPH86QIUMAePvtt5k9ezY7d+6ke/fuZZYvKiris88+o2HDhgCMHTuW6dOnG7d/8sknTJkyhYceegiAOXPmsGLFigp9tpkzZzJ8+HBGjx4NwMSJE9m+fTszZ87kvvvuIy4uDm9vb7p06YKVlRUBAQFERkYCEBcXh4ODA71798bJyYnAwEBatWpVofNXF6lJV5CLkyOnLQIBuHB0u4mjEUKI64uIiCj1Pjs7m0mTJtG0aVNcXV1xdHTkyJEjN61Jh4eHG187ODjg7OxsHPKyLPb29sYEDYZhMa+Uz8jIICkpyZgwASwsLGjTpk2FPtuRI0eIiooqtS4qKoojR44A8PDDD5OXl0eDBg14+umnWbp0KcXFxQA88MADBAYG0qBBAx5//HEWLVpEbm5uhc5fXaQmfQsuOjalSeYp8s/uBh43dThCiCpgZ2XB4endTHLeyuLg4FDq/aRJk1izZg0zZ86kUaNG2NnZMXDgQAoLC294HCsrq1LvNRoN+huMFVFW+cq8jV8e/v7+xMbGsnbtWtasWcPo0aN5//332bhxI05OTuzZs4cNGzbw119/MXXqVKZNm0Z0dLTZPeYlNelbUOzVgnOqDudzZHQiIWorjUaDvbVltS9VOerZli1bGD58OA899BBhYWF4e3tz5syZKjtfWVxcXPDy8iI6Otq4TqfTsWdPxYZbbtq0KVu2bCm1bsuWLTRr1sz43s7Ojj59+jB79mw2bNjAtm3bOHDA0OnX0tKSLl268N5777F//37OnDnD33//fRufrGpITfoWaCJG0PFAcxoUONDb1MEIIUQ5BQcH8+uvv9KnTx80Gg2vvfbaDWvEVeX5559nxowZNGrUiJCQED755BPS0tIq9AXlxRdfZNCgQbRq1YouXbrwxx9/8Ouvvxp7qy9cuBCdTke7du2wt7fnu+++w87OjsDAQJYvX86pU6e4++67cXNzY8WKFej1epo0aVJVH/mWSZK+BaH1DA/tn76UQ3ZBMY42chmFEObvww8/5Mknn6RDhw7UqVOHl156iczMzGqP46WXXiIxMZEnnngCCwsLRo0aRbdu3So0U1S/fv34+OOPmTlzJuPHjycoKIgFCxZw7733Aoa5nN955x0mTpyITqcjLCyMP/74Aw8PD1xdXfn111+ZNm0a+fn5BAcH88MPPxAaGlpFn/jWaVR1NxRcZdOmTbz//vvs3r2bhIQEli5dWuo5OaUUr7/+Ol988QXp6elERUUxb948goPL36P63Llz+Pv7Ex8fj5+fX6XFftfb60jMzOPnp9oQ0ejW5woVQphefn4+p0+fJigoCFtbW1OHc8fR6/U0bdqUQYMG8eabb5o6nEpzo39X5c1NJm2TzsnJoUWLFsydO7fM7e+99x6zZ8/ms88+Y8eOHTg4ONCtWzfy8/OrOdJr/cfxL/baPIPVP++ZOhQhhKhRzp49yxdffMGxY8c4cOAAzz33HKdPn+bRRx81dWhmx6T3aXv06EGPHj3K3KaUYtasWbz66qv07dsXgG+++QYvLy9+++03HnnkkeoM9Roerq64pWaTmHLIpHEIIURNo9VqWbhwIZMmTUIpRfPmzVm7di1NmzY1dWhmx2wbU0+fPk1iYiJdunQxrnNxcaFdu3Zs27bN5EnaMrQPvY84onFpxh8mjUQIIWoWf3//a3pmi7KZbZJOTEwEwMvLq9R6Ly8v47ayFBQUUFBQYHyflZVVJfE1btiQg+oslhcLyC/SYVuJzzYKIYQQUAufk54xYwYuLi7G5epn5iqTj4stbvZWFOsVx5Kq5ouAEEKIO5vZJukrU58lJSWVWp+UlHTDadGmTJlCRkaGcTl8+HCVxKfRaBjocYYZll+Qv+3LKjmHEEKIO5vZJumgoCC8vb1Zt26dcV1mZiY7duygffv2193PxsYGZ2dn4+Lk5FRlMUY4JDHEcj2ucX9V2TmEEELcuUzaJp2dnc2JEyeM70+fPk1MTAzu7u4EBAQwYcIE/u///o/g4GCCgoJ47bXX8PX1rfCco1XFPjACzoBn9lHDtJVVOJyfEEKIO49Jk/SuXbu47777jO8nTpwIwLBhw1i4cCGTJ08mJyeHUaNGkZ6eTseOHVm1apXZDDbg37QtxRu0uJJBcVo8lu4Bpg5JCCFELWLS29333nsvSqlrloULFwKGdt/p06eTmJhIfn4+a9eupXHjxqYMuZQATw9O4g9AUuwOE0cjhBAVd++99zJhwgTj+/r16zNr1qwb7qPRaPjtt99u+9yVdZwbmTZtGi1btqzSc1Qls22Trgm0Wg0X7A0Dsmeeir5JaSGEqDx9+vShe/fuZW7bvHkzGo2G/fv3V/i40dHRjBo16nbDK+V6iTIhIeG6A1oJA0nStymvThgAFkkV/88ghBC3auTIkaxZs4Zz585ds23BggVEREQQHh5e4ePWrVsXe3v7ygjxpry9vbGxsamWc9VUkqRvk21gG+CqzmNCCFENevfuTd26dY3Ng1dkZ2fz008/MXLkSC5dusSQIUOoV68e9vb2hIWF8cMPP9zwuP++3X38+HHuvvtubG1tadasGWvWrLlmn5deeonGjRtjb29PgwYNeO211ygqKgIMU0a+8cYb7Nu3D41Gg0ajKdWkefXt7gMHDnD//fdjZ2eHh4cHo0aNIjs727h9+PDh9OvXj5kzZ+Lj44OHhwdjxowxnqs89Ho906dPx8/PDxsbG1q2bMmqVauM2wsLCxk7diw+Pj7Y2toSGBjIjBkzAMNw1dOmTSMgIAAbGxt8fX0ZN25cuc99K8x2xLGaol5IBMWbtbjq09BnXEDrWs/UIQkhKlNhTsX3sbABi8t/XnXFoCsAjRas7G58XGuHcp/C0tKSJ554goULF/LKK68Y52L+6aef0Ol0DBkyhOzsbNq0acNLL72Es7Mzf/75J48//jgNGzYkMjLypufQ6/X0798fLy8vduzYQUZGRqn26yucnJxYuHAhvr6+HDhwgKeffhonJycmT57M4MGDOXjwIKtWrTLO9ezi4nLNMXJycujWrRvt27cnOjqa5ORknnrqKcaOHVvqi8j69evx8fFh/fr1nDhxgsGDB9OyZUuefvrpcl23jz/+mA8++IDPP/+cVq1a8dVXX/Hggw9y6NAhgoODmT17NsuWLWPJkiUEBAQQHx9PfHw8AL/88gsfffQRixcvJjQ0lMTERPbt21eu894qSdK3qaFPXU7iRxPiuHh8B15t+5s6JCFEZXrbt+L7PLwQQh8yvD76B/w0HAI7wog/S8rMCoPcS6X3m5ZRodM8+eSTvP/++2zcuNE4j/KCBQsYMGCAcdTFSZMmGcs///zzrF69miVLlpQrSa9du5ajR4+yevVqfH0N1+Htt9++ph351VdfNb6uX78+kyZNYvHixUyePBk7OzscHR2xtLS84UBU33//Pfn5+XzzzTc4OBi+rMyZM4c+ffrw7rvvGoeIdnNzY86cOVhYWBASEkKvXr1Yt25duZP0zJkzeemll4zzP7z77rusX7+eWbNmMXfuXOLi4ggODqZjx45oNBoCAwON+8bFxeHt7U2XLl2wsrIiICCgXNfxdsjt7ttkaaHlnK2hx3nGSek8JoSoPiEhIXTo0IGvvvoKgBMnTrB582ZGjhwJgE6n48033yQsLAx3d3ccHR1ZvXo1cXFx5Tr+kSNH8Pf3NyZooMzBpH788UeioqLw9vbG0dGRV199tdznuPpcLVq0MCZogKioKPR6PbGxscZ1oaGhWFiUzJXg4+NDcnJyuc6RmZnJhQsXiIqKKrU+KiqKI0eOAIZb6jExMTRp0oRx48bx118lg1U9/PDD5OXl0aBBA55++mmWLl1KcXFxhT5nRUlNuhLkejSHC2vRJlbtbQ8hhAn890LF97G4qjNUSB/DMTT/qhNNOHB7cV02cuRInn/+eebOncuCBQto2LAh99xzDwDvv/8+H3/8MbNmzSIsLAwHBwcmTJhAYWFhpZwbYNu2bQwdOpQ33niDbt264eLiwuLFi/nggw8q7RxXs7KyKvVeo9Gg1+sr7fitW7fm9OnTrFy5krVr1zJo0CC6dOnCzz//jL+/P7Gxsaxdu5Y1a9YwevRo452Mf8dVWaQmXQmsA1oDUCfziIkjEUJUOmuHii8WV9V/LCwN665uj77ecW/BoEGD0Gq1fP/993zzzTc8+eSTxvbpLVu20LdvXx577DFatGhBgwYNOHbsWLmP3bRpU+Lj40lISDCu2759e6kyW7duJTAwkFdeeYWIiAiCg4M5e/Zs6Y9qbY1Op7vpufbt20dOTklb/ZYtW9BqtTRp0qTcMd+Is7Mzvr6+10yTuWXLllKTMTk7OzN48GC++OILfvzxR3755RdSU1MBsLOzo0+fPsyePZsNGzawbds2DhyonC9cZZGadCXwaRLJon86c8qqEa/qitFYyGUVQlQPR0dHBg8ezJQpU8jMzGT48OHGbcHBwfz8889s3boVNzc3PvzwQ5KSkso9O2CXLl1o3Lgxw4YN4/333yczM5NXXnmlVJng4GDi4uJYvHgxbdu25c8//2Tp0qWlytSvX9847LOfnx9OTk7XPHo1dOhQXn/9dYYNG8a0adO4ePEizz//PI8//vg1UxbfjhdffJHXX3+dhg0b0rJlSxYsWEBMTAyLFi0C4MMPP8THx4dWrVqh1Wr56aef8Pb2xtXVlYULF6LT6WjXrh329vZ899132NnZlWq3rmxSk64Ejf08map/iv/l3UNCVvkfBRBCiMowcuRI0tLS6NatW6n241dffZXWrVvTrVs37r33Xry9vSs094FWq2Xp0qXk5eURGRnJU089xVtvvVWqzIMPPsh//vMfxo4dS8uWLdm6dSuvvfZaqTIDBgyge/fu3HfffdStW7fMx8Ds7e1ZvXo1qamptG3bloEDB9K5c2fmzJlTsYtxE+PGjWPixIm88MILhIWFsWrVKpYtW0ZwcDBg6Kn+3nvvERERQdu2bTlz5gwrVqxAq9Xi6urKF198QVRUFOHh4axdu5Y//vgDDw+PSo3xahqlavfDvefOncPf35/4+Hj8/Pyq7DzdZ23iaGIWXzwRwQPNKu9bnxCi6uXn53P69GmCgoLMZm4AUfPd6N9VeXOT1KQrSbi3HS00J8g+sMLUoQghhKglpPG0ktzjGM97NlNJO+YBjDB1OEIIIWoBqUlXEq/GbbmoXIjV+0NRnqnDEUIIUQtITbqShAT60LzgU0DDrgItdarmkTkhhBB3EKlJVxJHG0sa1HEE4NCFTBNHI4QQojaQJF2Jmvk6AxAbl3CTkkIIc1SZI1cJURn/nuR2dyXq6HqJ/9qMxW67FrqcNHU4Qohysra2RqvVcuHCBerWrYu1tbVx1C4hKkopRWFhIRcvXkSr1WJtbX3Lx5IkXYkC6jfGe0ca2mIF2cng6GnqkIQQ5aDVagkKCiIhIYELF25hrG4hymBvb09AQABa7a3ftJYkXYmaBvpwSvnQSHOB3Nh12LcZYuqQhBDlZG1tTUBAAMXFxTcdZ1qIm7GwsMDS0vK278hIkq5Ebg7WLLXqSCPdEjTr34YW/cHS5uY7CiHMgkajwcrKqspmNBKioqTjWCU702QkycoVu+w49DvmmzocIYQQNZgk6Uo2ultLZqtHAChe/y7kXDJxREIIIWoqSdKVzNvFlnr3PckhfSDWxVkUrnvr5jsJIYQQZZAkXQWe7NSIL+yfAsByz0K4GGvagIQQQtRIkqSrgI2lBQ/2G8xfujZo0ZGz/GVThySEEKIGkiRdRe4P8eJv/7EUKQsczv6NOrHO1CEJIYSoYSRJV6FRD3XlO31XAHKWvQS6YhNHJIQQoiaRJF2FGtR1JD1yImnKkaLMZAqSpG1aCCFE+UmSrmJPd23Ni5ZTuDv/A76MlYFNhBBClJ8k6SrmaGNJr979yMKeOX+fICEjz9QhCSGEqCEkSVeDfi3r0SbQjbyiYlb9+BmknTF1SEIIIWoASdLVQKPR8MaDobxi+T0jLkzj0u//NXVIQgghagBJ0tWkeT0Xcps+TJayY0WiCzqdTC4vhBDixiRJV6PH+vakq2Yer6X35ofoeFOHI4QQwsxJkq5GHo42PPNASwBm/hVLWnaBaQMSQghh1iRJV7PH7gqkiZcTAXlHyZjVjuzzh00dkhBCCDMlSbqaWVpo+WBQCybb/EL94tMkfzWUjMwsU4clhBDCDEmSNoHm9Vyo8+h8UnGmge4UG+Y+R2pOoanDEkIIYWYkSZtISOMm5PacA0Dfgj/4eO5HJGflmzgqIYQQ5kSStAn5RfYlreWzAPwn52Oen/cHiRmSqIUQQhhIkjYxt95vUuDZEldNDi9kv8+Qz/7hXFquqcMSQghhBiRJm5qlNTaPLERv7USkNpZ+Wd8x+PPtnL2UY+rIhBBCmJgkaXPgHoT2wY8BeN7yNwIydzHo822cvJht4sCEEEKYkiRpc9F8ALR6HC2KOTbzKMq8yODPt3EiWRK1EELcqcw6Set0Ol577TWCgoKws7OjYcOGvPnmmyilTB1a1ejxLtRpgodK5XPHL7iUnc8Hf8WaOiohhBAmYmnqAG7k3XffZd68eXz99deEhoaya9cuRowYgYuLC+PGjTN1eJXP2gEeXgDz76Nt8W76aLez/sTdFOv0WFqY9fcpIYQQVeCWknR8fDwajQY/Pz8Adu7cyffff0+zZs0YNWpUpQW3detW+vbtS69evQCoX78+P/zwAzt37qy0c5gdr1Do8S767Its2hBGVn4xB85n0CrAzdSRCSGEqGa3VD179NFHWb9+PQCJiYk88MAD7Ny5k1deeYXp06dXWnAdOnRg3bp1HDt2DIB9+/bxzz//0KNHj+vuU1BQQGZmpnHJyqqBQ25GjEB772TuaugJwD/HU0wckBBCCFO4pSR98OBBIiMjAViyZAnNmzdn69atLFq0iIULF1ZacC+//DKPPPIIISEhWFlZ0apVKyZMmMDQoUOvu8+MGTNwcXExLs2aNau0eKpbx+A62FCIdv8Ppg5FCCGECdxSki4qKsLGxgaAtWvX8uCDDwIQEhJCQkJCpQW3ZMkSFi1axPfff8+ePXv4+uuvmTlzJl9//fV195kyZQoZGRnG5fDhmjvLVKcGLvxiPY0xGR9QsGuRqcMRQghRzW6pTTo0NJTPPvuMXr16sWbNGt58800ALly4gIeHR6UF9+KLLxpr0wBhYWGcPXuWGTNmMGzYsDL3sbGxMX6BAMjMzKy0eKpbQF0XvrTugFdRKuezbGlp6oCEEEJUq1uqSb/77rt8/vnn3HvvvQwZMoQWLVoAsGzZMuNt8MqQm5uLVls6RAsLC/R6faWdw5xpNBpONx1Ft4L3+D07xNThCCGEqGa3VJO+9957SUlJITMzEze3kl7Ho0aNwt7evtKC69OnD2+99RYBAQGEhoayd+9ePvzwQ5588slKO4e5iwr25vvoC2w5cbnzWH4G2LqYNighhBDV4pZq0nl5eRQUFBgT9NmzZ5k1axaxsbF4enpWWnCffPIJAwcOZPTo0TRt2pRJkybxzDPPGG+v3wk6NPRAo4FjSdmkRy+GWWFwYq2pwxJCCFENbilJ9+3bl2+++QaA9PR02rVrxwcffEC/fv2YN29epQXn5OTErFmzOHv2LHl5eZw8eZL/+7//w9rautLOYe7cHKwJq2eoOacc2mioSS99FrKTTRyZEEKIqnZLSXrPnj106tQJgJ9//hkvLy/Onj3LN998w+zZsys1QAFRjeoA8LnNcPAMhZyLhkR9h7TNCyHEneqWknRubi5OTk4A/PXXX/Tv3x+tVstdd93F2bNnKzVAAZ0uJ+kNp7JQA/8HlnZwch1sn2viyIQQQlSlW0rSjRo14rfffiM+Pp7Vq1fTtWtXAJKTk3F2dq7UAAW0qe+GrZWWi1kFxOrrQfcZhg1r34Dze0wbnBBCiCpzS0l66tSpTJo0ifr16xMZGUn79u0BQ626VatWlRqgABtLCyKDDM+f/3M8BdoMh6YPgr4IfhkJBTVw6FMhhBA3dUtJeuDAgcTFxbFr1y5Wr15tXN+5c2c++uijSgtOlLhyy/ufEymg0cCDs8HZD1JPwfKJUFun7xRCiDvYLc9/6O3tTatWrbhw4QLnzp0DIDIykpAQGXSjKnQMNiTpHadSKSjWgZ0bDPgSNBZwYAlEf2niCIUQQlS2W0rSer2e6dOn4+LiQmBgIIGBgbi6uvLmm2/eMaOBVbcmXk7UcbQmr0jHnrPphpWB7eGBy7OOrZoC8bV4Ck8hhLgD3VKSfuWVV5gzZw7vvPMOe/fuZe/evbz99tt88sknvPbaa5UdowC0Wo3xUax/Tlws2dB+DDTrZ2ifXvKEPD8thBC1yC0l6a+//povv/yS5557jvDwcMLDwxk9ejRffPFFpU5VKUrreCVJXz2/tEYDfedAnSaQlQBHlpkoOiGEEJXtlsbuTk1NLbPtOSQkhNTU1NsOSpStU3BdAPafzyAjtwgXeyvDBhsnGPwdJOyD8IdNGKEQQojKdEs16RYtWjBnzpxr1s+ZM4fw8PDbDkqUzdvFlkaejigFW0+mlN5Yt7EkaCGEqGVuqSb93nvv0atXL9auXWt8Rnrbtm3Ex8ezYsWKSg1QlNaxUR1OJGez+UQKPcJ8yi6UnQzLnocH3jQkbyGEEDXSLdWk77nnHo4dO8ZDDz1Eeno66enp9O/fn0OHDvHtt99WdoziKmW2S//bqpfh2Cr47Tl5floIIWqwW6pJA/j6+vLWW2+VWrdv3z7+97//MX/+/NsOTJTtroYeWGo1xKXmEncplwCPMubv7v4O5KZCj/cMHcuEEELUSLc8mIkwDUcbS1oFuAKw+epHsUoV8oQnfoO6jckuKOaVpQf4cvOpaotRCCFE5ZAkXQN1bGTo5b3lxA1ueQMXswp4ZP42TkWvZPXKpZxPz6uO8IQQQlQSSdI1UMdgw2QbW05cQqcvu835TEoOA+ZtpU7CRr6zepvPrT5k/ca/qzNMIYQQt6lCbdL9+/e/4fb09PTbiUWUUws/V5xsLMnIK+Lg+Qxa+LuW2n7gXAYjFu4kJbsQG7fWpFg0xSv7ML33PoMuciUWPmGmCVwIIUSFVKgm7eLicsMlMDCQJ554oqpiFZdZWmi5q+HlqSv/dct707GLDJ6/jZTsQkJ9nVk0+n5cnvmTgzTElSz0C/pA4gFThC2EEKKCKlSTXrBgQVXFISqoU3Ad1hxOYvPxi4y5rxEAv+09z6Sf9lGsV0Q18uCzx9rgZGsF2LI8/FOKY56jZeEp+PpBGLYMvKVGLYQQ5kzapGuoK89L7zmbTm5hMV9uPsWEH2Mo1isebOHLguGRlxO0Qd/2zXiicAox+oaQlwpf94GE/aYKXwghRDlIkq6hguo4UM/VjkKdnqe/2cX//XkEgCejgpg1uCXWlqV/tU19nAnyr8fjhVNIdm4OeWnwzYOG8b6FEEKYJUnSNZRGoyGqUUkvb4ApPUJ4rXdTtNqyBzAZ0tafLOwZqf8vql6EIVF/LYlaCCHMlSTpGuzuxobnpS21Gj4c1IJn7mmI5gYjjPVu4Yu9tQUHUmDP3f8Dv7aQn25I1BdiqidoIYQQ5SZJugbr0dyHl3uE8MOou+jf2u+m5R1tLOkT7gvAon3p8NivJYn6m76QHl+1AQshhKgQSdI1mIVWw7P3NKRtffdy7zM40h+AFQcSyFB2lxN1JLR8FFxunuiFEEJUH0nSd5hW/q408XIiv0jPspjzYOtseByr29slk3HkpEBRvmkDFUIIIUn6TqPRaBjc1lCbXhx9+fa2lV1JgtYVw4+Pwf+6wKWTJopSCCEESJK+Iz3Uqh7WFloOXcjk4PmM0htTT0HKMUg9Y5LYhBBClJAkfQdyc7CmW3NvAH7YGVd6Y93G8Ow/MPhb8GhYsl6vq8YIhRBCgCTpO9aQy7e8l8VcILewuPRGZ19oeF/J+5Pr4fN74GJsNUYohBBCkvQd6q4GHgS425NVUMyKA4nXL6gU/PUaJB2A+ffC3kWGdUIIIaqcJOk7lFZb0oHsx+i46xfUaOCxXyDoHijKhd9Hw4KecG53NUUqhBB3LknSd7CBbfyw0GqIPpPGieSs6xd08oLHl0LnqShLO4jbCl/eDz+PhLSz1RewEELcYSRJ38G8nG25r4knAD9GX3+0sYy8Ir7eHk/33W3ppWaRENQf0MDBn2FOhOF2eF569QQthBB3EEnSd7hHLt/y/mXPeQqL9cb1Sil2n03lhSX7aPf2Wl5fdoijiVkcznEi6uhAfm37PSrobtAVwtbZMLsV7PgcdEWm+ihCCFHrSJK+w93bpC6eTjak5hSy5nAS6bmFLNhymm6zNjFg3jZ+2XOO/CI9TbycmNanGUMi/dErmLhZ8YLtdAoHLYY6TQxzVK+cDHPbyWQdQghRSSxNHYAwLUsLLQ9H+DF3/Une+OMQGXlFFFyuUdtaaekT7suQdgG08ndFo9GglCLE25npyw/z694LnEpxZf5jf+N5Ygmsfxuyk8G53g3PGXcpl03HL9KjuTcejjbV8TGFEKJG0ihVu5+nOXfuHP7+/sTHx+PnJxNIlCXuUi53v7/e+D7E24mh7QJ4sGU9XOysytxny4kURi/aQ0ZeEV7ONsx/PIIWdbWGuamDOpUUXDIM6rVBtRnOtnOFfLXlDOuOJqEUBHrY893Idvi721f1RxRCCLNS3twkSVoA8O32s5xMzqZfq3q08HO54bzUV5y9lMNTX+/ieHI2NpZa3hsYTt+WV9Wi43bAV13Raa14zOFLtl0sSfhOtpZk5Rfj6WTDNyMjCfF2roqPJYQQZqm8uUludwsAHr8rsML7BHo48OvoDkxYHMO6o8mMXxxDbGIWk7o2ISkrn0UH7cjSPIdTQQrbcq2wt7ZgQGs/xtutQNOoM48uyyE2KYtBn21jwYhI2gS6VcEnE0KImktq0uK26fSKD/6K5dMNhlmzgj0dOZWSg05v+Kfl52bHsPb1GdTWH5f0w/D53QAUe7fiu+w2fJ7SgnQrTz57vA33NK5rss8hhBDVRWrSotpYaDVM7h5CE28nJv+8n+PJ2QDc1cCd4R2CeKCZFxbaK3NV20PoQ3D4dywT9zKcvQy3hV36xqz69i7ye42k210tTfdhhBDCjEhNWlSqQxcyWHUwkR7NfWjme4N25qwkOLIMDi1Fnd2KBsM/Q73ScNG9NV7th0CzvuDoWU2RCyFE9SlvbjL756TPnz/PY489hoeHB3Z2doSFhbFr1y5ThyWuI9TXhRe6NrlxggbDUKORT8OIFWgmHkHf7R3OOoSh1Si80nbDikmoD5rAlw/ArgXVE7wQQpgZs07SaWlpREVFYWVlxcqVKzl8+DAffPABbm7SwahWcfZB2/45AiZt5ouIP3izaCgx+oZolB7O7YRLJ0rKFuXBzi/g0kmZjUsIUeuZdZv0u+++i7+/PwsWlNSkgoKCTBiRqEoajYane9/NAjd/+v1xGB8uMaXJBR4M71lS6OxWWDHJMGDKfw6VrM9KBEcvw6xdQghRS5h1TXrZsmVERETw8MMP4+npSatWrfjiiy9MHZaoYiOigvhwUAsS8GBcbBjbcq969lprCfU7QeNuJQlZr4NPIuD9hrBoEGx8D06sk0k/hBA1nlnXpE+dOsW8efOYOHEi//3vf4mOjmbcuHFYW1szbNiwMvcpKCigoKDA+D4r6wZTMAqz1b+1H7vOpvH9jjhe+mU/qyZ0wt7aEhrcY1iuvtWdHge6AijMguOrDcsVdRpDvQio1xq8w8G7OVg7VP8HEkKIW2DWvbutra2JiIhg69atxnXjxo0jOjqabdu2lbnPtGnTeOONN65ZL727a56s/CK6fbSJCxn5PBkVxNQ+za5fuLgAEg/C+V1wLhrO7YK002UU1IBHI/AOg25vg7NPlcUvhBDXUyt6d/v4+NCsWek/zE2bNiUuLu66+0yZMoWMjAzjcvjw4aoOU1QRJ1sr3u4fBsCCrafZdSb1+oUtbcCvDbR7BgZ8CeNj4MWT8OgSuHsyBHcFR29AwaXjcGgp2DiW7L/xPcOt8uNrqvQzCSFERZj17e6oqChiY2NLrTt27BiBgdcfwtLGxgYbm5KZlTIzM6ssPlH17m3iycA2fvy8+xyTf97PivGdsLWyKN/ODnUMbdeNu5Wsy06GxP2QehpsnErWn1wPcVsNA61cER8Nf08Hnxbg3cLw06MhaMt5fiGEuE1mnaT/85//0KFDB95++20GDRrEzp07mT9/PvPnzzd1aKIavdarGZuOXeRUSg4frT3GlB5Nb/1gjp7QqMu167v+H5zfDfU7lqw7vwtObzIsV1jaQZ1gqNvEMI/2ldfuDcHS+tbjEkKIMph1mzTA8uXLmTJlCsePHycoKIiJEyfy9NNPl3t/GXGsdlhzOImnv9mFVgO/jo6ipb9r1Z809TSc2WyYfjNhPyQegOK8sstqLMA9CPzvgn5zS9ZnJYK9B1iUPeWnEOLOVGvG7u7duze9e/c2dRjCxB5o5kXflr78HnOByT/v44/nO2JjWcW3nd2DDMsVeh2knoKUY3Ax1vAz5RhcPGboWX7pBDj8axjTL7tA5gV4aq2hhznAhb2QcgJc/MDZF5x8pBYuhCiT2SdpIa54vU8oW06kcCwpmzl/n+CFrk2qNwCtheH2dp1gCOlVsl4pyEowJG7NVX0xdcWQmwpKZxh85YoDP8O2OaWP7eBp6GnuXM+QuJ19Da+dfC4v3mArc24LcaeRJC1qDHcHa6b3bc7oRXv4dMNJuoV607yei6nDMgyqciWxXs3CEqacg+yk0hOFuAZCYEfIPG+oZesKICfZsCTsK/scgR1hxJ8l7/+YAFb20PE/4Hh5es/CXEMvd+nYJkStIUla1Cg9w3zoGebNigOJvPjzfpaNjcLKwoyfJNRqr30Wu90oVOTTaDQaQy08N7UkYRt/XoDMc4bZwrISDROSXKErhj1fg9JD1LiS9evfgh2fGb4suPgbbqe7+BleO9cz1MadvMG+jiEuIYTZkyQtapw3HmzOtpOXOJKQybwNJxnXOdjUIZVbsU7PpxtOMn/TKYZE+vPfnk3ROHiAgwf4hF9/R72u5LXSGXqjZyWCQ92S9ZnnQV9sGIEt/fpjCaCxMIxz7uQFDTtD59dKtsWuAjtX8G1lqJULIUxKkrSoceo62TDtwVDGL47hk7+P0zXUixDvW2+vLdbpOXQhk/S8Ihp5OuLrYmuo5Vays5dymPBjDHvj0gH4YvNpCor1vPFg6M3Pd/UtbEsbaD/m2jID/mcYRS09HjLiIePc5SXeUDPPSoSci4Ykn3XBsHg0KtlfVwQ/DDa8fvFkSZL++y04ttLwhcDB01A7d/UH1wBwCTC8t7K99QsjhLguSdKiRnqwhS9/7LvA2iPJPPjJFprXc6Z1gBttAt1oHeiGl/P1k0aRTs/B8xlsP5XKjtOX2HUmjeyCYuN2RxtLGns50sTbicZeTjTxcqKxtxN1HG+tZqmU4sfoeKYvP0xuoQ4nW0v6t6rHN9vP8s22swDlS9Q3o7W4qm28XdlldMWGRJ2VYGgrt69jjLEwLwsbv7aQewnsrpoO9tJxw+NnN+LodTlp+xsSeL0IaPbgVcc4aTimnZvMVCZEBZj9c9K3S56Trr2SMvN5/H87OJaUfc22eq52tA50o3WAK20C3SjS6dl+KpXtpy6x+2wauYW6UuWdbS3xdLblTEoOxfqy/0t4OFjT1MeZbqFe9AjzKVfSvpRdwMu/HmDN4SQA2gW58+HgltRztWPJrnhe+mU/SsET7QMrJ1HfoolLYvht73kiAt3pGupF12beBHjYGzamHIe0M5CTYkjsGfGXb6lf/lmUc+0Bwx+B/p8bXhcXwP9d7jj30lnD7XSAf2bB2S1g63o5gbuWfm3nZvgS4ehpGB1OkruoRcqbmyRJixpNKUVcai67z6axJy6NPWfTOZqYyXXyrJGLnRXtgtxp18CDdkHuNPVxxkKrobBYz5lLOcQmZnEsKcv482xqbqmJt7QaiGpUhz7hvnQL9cbF/trBStYfTebFn/eTkl2AlYWGSV2b8FSnBlhoS5LN7STqPXFpzN94imAvx9t6HC0xI58O76y75pqFeDvRNdSbrs28CPV1LjsupSAvDdLPliTujHOGNu0Wl2+dZyfDJ22gKBdeSylJtkuegMO/ly9ISztDsg7pDd3fLlm/9zvDYDEN7pNb7qJGkSR9mSTpO092QTH749NLEndcOhZaDZH13WnXwJ27GnjQxMsJrbb8NbO8Qh0nkrPZdiqF5fsT2H8uw7jNykLD3cF16dPCly7NvNBq4K0/j7Boh6HzVmMvRz4a3JJQ37IfF6tooj51MZv3V8ey8mCicd3aiXfTyNPpuvvcyLwNJ3l31VFa+LnQr1U9/jqUxM4zqeiuytr1XO14oJkXUY3qUFisJzW3kNTsQtJyC7mUU0haTsnP7IJigr0caRPgRkR9Q/ODp5MtFBeWHrTl7DbDADD56YZEn5dOUU4qOekpFGanos1Px1llYF181Z2Slo+VjOhWlAdveRteX11DXzMVjv1lSOpO3oafDnXBxtlQI7d1Mby2vfzexhmsHaXHu6hWkqQvkyQtqsKZlBz+PJDAH/sucDSxZM5yG0stbvbWJGbmA/BkVBCTuze56aQg5UnUyVn5fLz2OIuj49HpFVoN1HG0ITmrgKc6BvFq7xtM5XkdSike+GgTJ5Kzead/GI9EBgCQllPI30eT+etwIhuPXSS/SF/hY18twN2eiMv9BSLqu9HY04nswmIOns/g4PkMDpzP5OD5DE6nXHvr/MOHgunf2NpQI7dxAs/LY7fnpsLSZw0JfuRfJTX0Hx6F2D+vOc4NhfSGRxYZXisFX3U3zDs+4EuwdzesP74WLh65nOBdDEne1gVsXEreS494UU6SpC+TJC2q2rGkLJbvu8Af+xOMScbb2ZaZD7egY3Cdch/neok6u6CY+RtP8sXm0+QVGdrSO4d4Mrl7COfSchn59S7cHazZNuX+Cg+VGhOfTr+5W7C10rLzlS4421572z6vUMc/J1L461AiB85n4GRribuDtXFxs7fGw9Hw093BGlsrCw5dyGDXmTR2n00jNimLf/+VsbOyMH6Wf6vnakfzeobmhxUHErHUalg4IrL81zL1FKSdNbSfZycZkntOChRkQn4mFGRAQdbl15mGx9ZaPAoPzTPsX5gLb19+tn3KuZLZ0n4fY7i9fiOWtqVr6fU7Gh6Xu2LT+6C1gjbDSjrn5aSArhDs3OWW/R2k1ozdLYS5a+zlxMSuTfjPA405dCGTfefS6RXmg6t9xcbjHhThD8BLv+znm21nUQoaeToye91xLuUUAtDS35UpPUJo18ADgIZ1HfBytiEps4A1h5PoHe573eOX5Zfd5wDoFupdZoIGsLO24IFmXjzQzKvM7WVp7OXEQ60Mf3gy84vYG5fO7jOp7DqbRkx8urHjXj1XO8LquRDm50Lzei4093XG43KHPL1e8R+LGH6PucCz3+3mp2fb09SnHI/auTcwLOWhlOG2ubrqC4PWEgZ/BwXZYOVQst4v0tAJ7kpyz88wvM7PMIzdDlCcb1hykg3vnXxLn2vDu6AvgrCBJUl6yyzY+onhtZWDoY3d3t2w2LlddXv+Su3d1fDYW8BdJccuyDKMQCejzdU6kqSFqCQajcaQaG5jqNKrE/W3288a1wfVcWBytyZ0b+5d6ja4pYWWQRH+fPL3CRbvjK9Qki4o1rFs3wUABrapurtMzrZW3NO4Lvc0Ngy8UqzTczolhzqONrg5XP+LjFar4b2B4SRm5LPjdCojFkTz25govF0qsbap0YC1fel1ltbQtM+1ZdsMMyxl0etKaur5l2vqBVklt8rBMEJcxJOG9bauJeuLCw0DzCidoad8Rg5k3GAwGoD6nWD48pL3H7cwPDo3egd4hhjW7VoA+5cYbttbOxiSuJXd5cW+jJ+2ht70ge1Ljpt21jAevaOXTAJjIpKkhTAzVxL1y7/sx93Bhgldghnc1v+6w58OivBnzvoT/HMihfjUXPzd7css92/rjiSTkVeEt7MtHRqW/7b87bK00BLsVb5ObjaWFsx/PIIBn23lRHI2IxZGs+SZu3C6Tq3fZLQWJc+B36hMz/cAyMgrwlGvDD39e74HPd41JPe8VENbe+4lw5KX/q9a++X33v8ana7gcuc666tq/pdOQNzWin0OnxbwzFXzp3/dx9Bzf+Qa8I80rNv1FWyaeflxOdfLtf0rr10Nr7UWhjsH6nJfBhvnkt7+APsWQ2EOBHc1PFcPJV9sbF0MXxrkkTtAkrQQZmlQhD/3NK6Li53VTTud+bvb07FRHTYfT+HH6HgmdSvf41g/X77V3b91vVKPhZkbF3srFgxvy0OfbuVIQiajF+3hq+FtyzVm+7m0XOZvOsWlnELe7hdW5qNy1SEpM5/tpy5dXlI5nZKDn5sdk7uH0Cfcx3B35EqSK++t+qu9HGdIeld6uAO0egz82kJhtmFbUd7lJbeM15d/1vnXELsW1mBhY2hrvyI7+fIY8+fLH597w9JJestsSD4Ej/1SkqQPLYVlzxteay0v98Z3NJzb8nIM/35t5wa9ZpYcN3aVoSNhYAdwCzSsK8y9nPydDfvUsOQvSVoIM3WjUdP+7ZG2AWw+nsJPu+OZ0CUYy5sksOSsfDYeuwjAgCq81V1Z/N3t+Wp4BIM/387m4ym8svQA7w4Iv+6jaufT85i7/gQ/7YqnSGfotXYxs4BvRkbe9EvP9ej0ipj4NHR6cLCxwMHaEgcbSxxsLLCzsigVS3JWvnHwnO0nL3GqjF7r59LyGPfDXv63+RT/7dnU2M/glljZXtvpzLNpSU/4W/X8rmvXtX3KUAPOTzfU9PPSSl5f+XmlBq3RXL5d7l36GI27GuZqd77q315RvqGs0hs68+WlGpYbcahbOklvnW0YIOfhhSVJ+vhf8NPlZgqt1eVOfVe18V95faXDn7WjodNfm+ElCT3jvKE5wqGuoXmgGkmSFqIWeKCZFx4O1iRlFrAh9iJdbtLJ6/e9F9DpFa0CXGlY17Gaorw94X6uzHm0FU9/s4slu87h72bP8/+aXOV8eh6frj/BkquS810N3Dl0PpOdZ1J5Yck+PhnSqkLPyIOhh/uob3ex+XhKmds1GnCwtsTe2gJLrYYLGfnXbA/1deauIA/aN/SgeT0XlkTHM2/jSfady2Dw/O10bebFSz1CzP/34VDHsNyOLtOuXdduFEQ+baj152cYlqLcks54xQXX/tT+K4XVa2OoaZdK/nmABlCGTntXmhJuxMIGIkaUvF8xCWJXQJ+PDcm7GkmSFqIWsLbUMqCNH/M3nWJxdNwNk7RSynire0Br869FX61zUy+m923Oq78d5IM1x/B1tWNAGz8upOfx6YYT/Bhdkpw7NPRgfOdg2jXwYOuJFIYt2MmfBxLwcbGt0DPl2QXFjFwYzY7TqdhaafFxsSOnoNiwXO6lrpSh3JUx4DUaaOrtTPuGHtzVwIPIIHdc7Erfan++czCDI/2ZtfY4i3fG8dfhJNYdTWZouwDGdw429nK/o2g0hlvcNo7gUq/i+3d989p1LYdA+GDDbX/jY3hXtfMXZJS8Lsw23Br/9zODGq1h1DubWxsw6HbIc9JC1BInkrPp8uFGtBrY+nLn6/aCPng+g96f/IO1pZbo/3YxWTvt7Zix8gifbzyFpVZDr3AfVhxIKDM5X+33mPOMXxwDwGu9mzGyY9BNz5OZX8Twr3ayJy4dRxtLFo5oS0T9kh7ber0ir0hHTmExOQU6cgqKyS/S0cjTsUKP4B1PyuKdlUdZd9Tw6JajjSXP3duQkR2Dbvn2/BUZeUWcSM4m3M/FvOderwmUqrQ2bXlOWog7TCNPRyLru7PzTCo/745n7P1lz7N9pRb9QDOvGpmgAV7qFsL5tDyW70/g9xjDY2TtG3gwvkswd12nbbdvy3pcSM/n3VVH+b8/D+PtbEuvcJ/rniMtp5AnvtrJgfMZuNhZ8c2TkbTwdy1VRqvVXG6XtoTbqGQFeznxv+Ft2XbyEm+vOMKB8xm8vzqWZTEX+GV0Bxxtbu1PdV6hjkGfbSM2KQtnW0u6NPOie6g3dzeue9vJ/3Zk5Rdhbamt8OA7VSEzv4h1R5KIiUunsbcTHRrWob6Hfdn9HUzQ6UyStBC1yCOR/uw8k8qPu+IZfW+ja9peC4v1/B5j6JVblc9GVzWtVsPMh1tgodWQmVfEM/c0vG5yvtqz9zQgISOPb7ad5T9LYqjrZENkkPs15S5mFfD4/3ZwNDELDwdrvh3Zjma+tz5neXm1b+jB72OiWLbvAv/352Fik7J4dekBPhrc8pZmSJu+3HAMgMz8Yn7dc55f95zH3tqC+0I86R7qzX0hnrf8JaC8Cov17IlLY9Oxi2w6fpGD5zNxuDxITp8WvnQKrou1ZfXV8tNyCllzOIkVBxPYciLFeBfmCl8XWzo0qkNUIw86NKxToU6clU1udwtRi+QV6oh8ey1Z+cV8OzKSTsF1S21ffSiRZ77dTV0nG7a9fP9Ne4HXRjq94tnvdrPmcBIudlb88lz7UpOTJGbkM/TL7Zy8mIOnkw2LnmpX7ue6K9OuM6kMnr8dnV7x7oAwBrcNqND+f+5PYMz3e9Bo4OsRhl7tKw8msPpgYqmObdaWWu4OrsM9TTzRYGhbz7ncvm5oe9cZX+cX6/ByssXf3R5/d3sCLi/+7nbYW5dO9GdScth8/CIbj6Ww7WSKsf2+LM62lnRv7k3vcF86NPSokn+XyVn5rD6UxKqDCWw/VXoCmWBPRzo09OBIYhZ749KuSdoN6zoQ1agOHRrWoX0Dj0q5AyVjd18mSVrcaab+fpBvtp2lV7gPcx9tXWrb09/sYs3hJJ65uwFTet7m4zk1WF6hjke/3M7euHTqudrx6+gOeDnbci4tl6Ff7uDspVx8XWxZ9PRdBNVxuPkBq8inG07w3qpYbK20/D6mI028y/dlIT41l56zN5OVX8zoexsyuXuIcZtSiv3nMlh5MJFVBxM4cym3UmKt42hDgLsd3i62HDyfSVxq6eN6OFjTKbgOnYLr0im4DvFpeSzff4E/9yeQnFVQqlz35t70aeFL2/rut/0M/+bjF/lk3Qmiz6aW6g/WzMeZnmHedG/uQyPPkh71eYU6os+ksuVkCttOXuLA+YxS+4XVc+GP5zveVkwgSdpIkrS40xy+kEnP2ZuxstCwfUpnYy/hS9kFtHt7HcV6xV//uZvGJqgdmpPUnEIGzNvK6ZQcmvk48/7D4Yz6Zjfn0/MIcLdn0VPtyj16W1XR6xXDF0az6dhFGnk6smxs1DU11n8r0ukZ9Pk29sal0yrAlSXPtL9uhzGlFLFJWaw6mMjeuHRsrbQ42FjieLmd3dHGEgdrC+Nra0stiZn5xKfmEZ+aS9zlJSOv6JpjW1loaBPoRqdgw5CwzXycy3z0TadXRJ9J5Y99F1h5MJHUy+PUAzSo48DsIa1uaahdpRTzN53inVVHjUm2pb8rPZp706O5DwEe5fvdZuQWse3UJbaeTGHryUt0DvGslC+4kqQvkyQt7kQPzvmH/ecyeKVnU56+2zCC1Vf/nGb68sOE+7mwbOzt1wRqg7hLufSft4WU7NKJ4fun76rcMcJvQ0p2AT0/3kxyVgED2/gx8+EWNyz/3qqjfLrhJE62lqwY16lavmhk5BURn5pLfGou59PzqO/hwF0NPSrc1l2s07P15CWW77/AqoOJZOYXY22h5b89QxjWoX652+Xzi3S8/Mt+frvcqfCRtv6M6xyMr+vtD0SiuzKc620qb2668xqkhLgDPHK5/XJxdBxXvof/sqdmPhtdlQI87PlqeFvsLvd0buzlyOJnzCdBg+E28uwhrdBqDD3zr8xcVpZ/jqcwb+NJAN4dEF5tdwJc7KxoXs+FHmE+PNWpAV2aed1SZzRLCy13N67LewNbsGnyfTzQzItCnZ5pfxzm2e92k5F7bY393xIy8hj0+TZ+i7mApVbDm31DmdE/rFISNFDtQ+hKkhaiFnqwpS/21hacvJjDrrNpHEnI5NCFTKwsNDzYomLTWdZ24X6uLHq6HWPva8TiUe3xdDKfBH3FXQ08mNClMQCv/naQE8lZ15RJyS7gP0tiUAoebRdAz7DrP15WE7jaWzP/8TZM7d0MKwsNqw8l0euTzeyNS7vuPrvPptLnky3sP5eBm70V345sx+Pty18DN0eSpIWohRxtLOl9+RngH3bGGWtfnUO8bjg95J2qdYAbk7o1wd2Mr82Y+xoR1ciDvCIdYxbtJb+opLe0Xq94Yck+LmYV0NjLkakVGFHNnGk0Gp7sGMQvz3UgwN2ec2l5PPzZNr7YdIp/t9QuiY5nyPwdpGQXEOLtxLKxHWnf8DbGQzcTkqSFqKUeiTTc8l5xIIGle2v+s9F3Ogutho8Gt6SOow2xSVm88cch47Yv/znFxmMXsbHUMufR1iYdqKQqhPu5snxcR3qGeVOsV7y14ghPfb2LtJxCinR6pi07xORf9lOo09OjuTe/PNfB5J3+KoskaSFqqVb+rjTxciK/SM+lnEI8HKy5p0ndm+8ozJanky0fP9ISjQZ+2BnP7zHn2RefznurYgF4vU9ore2172xrxdxHW/Nmv+ZYW2pZdzSZnrM3M/TLHSzcegaAiQ80Zu6jrQ0jwNUSkqSFqKU0Gg2D2/ob3/drVU/Gbq4FohrV4fn7GgHw318PMHrRHor1il5hPgyJ9L/J3jWbRqPh8bsCWTq6A0F1HEjIyGfn6VQcrC34/PE2jOscXOEZzsyd/I8Vohbr37oeNpeHW5Re3bXH+C6NaRfkTk6hjvPpedRztePt/mE1uoNURYT6GgYUGRLpT0SgG7+OjqJbqPfNd6yBas89ASHENVztrfn6yUgy8oqqZexpUT0stBpmD2lFr9mbycgrYvaQVtdMhVnbOdpYMqN/uKnDqHKSpIWo5coz8YSoebycbVkxvhO5BTrqm3DoUlG1JEkLIUQN5elke1tTZArzJ23SQgghhJmSJC2EEEKYKUnSQgghhJmSJC2EEEKYKUnSQgghhJmq9b279Xo9AAkJCSaORAghhDC4kpOu5KjrqfVJOikpCYDIyEgTRyKEEEKUlpSUREBAwHW3a9S/5/uqZYqLi9m7dy9eXl5otbd3dz8rK4tmzZpx+PBhnJzk4cTykGtWcXLNKk6uWcXJNau4yrxmer2epKQkWrVqhaXl9evLtT5JV6bMzExcXFzIyMjA2VmGWCwPuWYVJ9es4uSaVZxcs4ozxTWTjmNCCCGEmZIkLYQQQpgpSdIVYGNjw+uvv46NjY2pQ6kx5JpVnFyzipNrVnFyzSrOFNdM2qSFEEIIMyU1aSGEEMJMSZIWQgghzJQkaSGEEMJMSZKugLlz51K/fn1sbW1p164dO3fuNHVIZmvTpk306dMHX19fNBoNv/32m6lDMnszZsygbdu2ODk54enpSb9+/YiNjTV1WGZt3rx5hIeH4+zsjLOzM+3bt2flypWmDqvGeOedd9BoNEyYMMHUoZitadOmodFoSi0hISHVdn5J0uX0448/MnHiRF5//XX27NlDixYt6NatG8nJyaYOzSzl5OTQokUL5s6da+pQaoyNGzcyZswYtm/fzpo1aygqKqJr167k5OSYOjSz5efnxzvvvMPu3bvZtWsX999/P3379uXQoUOmDs3sRUdH8/nnnxMeHm7qUMxeaGgoCQkJxuWff/6pvpMrUS6RkZFqzJgxxvc6nU75+vqqGTNmmDCqmgFQS5cuNXUYNU5ycrIC1MaNG00dSo3i5uamvvzyS1OHYdaysrJUcHCwWrNmjbrnnnvU+PHjTR2S2Xr99ddVixYtTHZ+qUmXQ2FhIbt376ZLly7GdVqtli5durBt2zYTRiZqs4yMDADc3d1NHEnNoNPpWLx4MTk5ObRv397U4Zi1MWPG0KtXr1J/08T1HT9+HF9fXxo0aMDQoUOJi4urtnPX+lmwKkNKSgo6nQ4vL69S6728vDh69KiJohK1mV6vZ8KECURFRdG8eXNTh2PWDhw4QPv27cnPz8fR0ZGlS5fSrFkzU4dlthYvXsyePXuIjo42dSg1Qrt27Vi4cCFNmjQhISGBN954g06dOnHw4MFqmZhEkrQQZmjMmDEcPHiwetu+aqgmTZoQExNDRkYGP//8M8OGDWPjxo2SqMsQHx/P+PHjWbNmDba2tqYOp0bo0aOH8XV4eDjt2rUjMDCQJUuWMHLkyCo/vyTpcqhTpw4WFhbGuamvSEpKwtvb20RRidpq7NixLF++nE2bNuHn52fqcMyetbU1jRo1AqBNmzZER0fz8ccf8/nnn5s4MvOze/dukpOTad26tXGdTqdj06ZNzJkzh4KCAiwsLEwYoflzdXWlcePGnDhxolrOJ23S5WBtbU2bNm1Yt26dcZ1er2fdunXS9iUqjVKKsWPHsnTpUv7++2+CgoJMHVKNpNfrKSgoMHUYZqlz584cOHCAmJgY4xIREcHQoUOJiYmRBF0O2dnZnDx5Eh8fn2o5n9Sky2nixIkMGzaMiIgIIiMjmTVrFjk5OYwYMcLUoZml7OzsUt80T58+TUxMDO7u7gQEBJgwMvM1ZswYvv/+e37//XecnJxITEwEwMXFBTs7OxNHZ56mTJlCjx49CAgIICsri++//54NGzawevVqU4dmlpycnK7p4+Dg4ICHh4f0fbiOSZMm0adPHwIDA7lw4QKvv/46FhYWDBkypFrOL0m6nAYPHszFixeZOnUqiYmJtGzZklWrVl3TmUwY7Nq1i/vuu8/4fuLEiQAMGzaMhQsXmigq8zZv3jwA7r333lLrFyxYwPDhw6s/oBogOTmZJ554goSEBFxcXAgPD2f16tU88MADpg5N1BLnzp1jyJAhXLp0ibp169KxY0e2b99O3bp1q+X8MguWEEIIYaakTVoIIYQwU5KkhRBCCDMlSVoIIYQwU5KkhRBCCDMlSVoIIYQwU5KkhRBCCDMlSVoIIYQwU5KkhRBCCDMlSVoIUek0Gg2//fabqcMQosaTJC1ELTN8+HA0Gs01S/fu3U0dmhCigmTsbiFqoe7du7NgwYJS62xsbEwUjRDiVklNWohayMbGBm9v71KLm5sbYLgVPW/ePHr06IGdnR0NGjTg559/LrX/gQMHuP/++7Gzs8PDw4NRo0aRnZ1dqsxXX31FaGgoNjY2+Pj4MHbs2FLbU1JSeOihh7C3tyc4OJhly5YZt6WlpTF06FDq1q2LnZ0dwcHB13ypEEJIkhbijvTaa68xYMAA9u3bx9ChQ3nkkUc4cuQIADk5OXTr1g03Nzeio6P56aefWLt2bakkPG/ePMaMGcOoUaM4cOAAy5Yto1GjRqXO8cYbbzBo0CD2799Pz549GTp0KKmpqcbzHz58mJUrV3LkyBHmzZtHnTp1qu8CCFFTKCFErTJs2DBlYWGhHBwcSi1vvfWWUkopQD377LOl9mnXrp167rnnlFJKzZ8/X7m5uans7Gzj9j///FNptVqVmJiolFLK19dXvfLKK9eNAVCvvvqq8X12drYC1MqVK5VSSvXp00eNGDGicj6wELWYtEkLUQvdd999xvmpr3B3dze+bt++falt7du3JyYmBoAjR47QokULHBwcjNujoqLQ6/XExsai0Wi4cOECnTt3vmEM4eHhxtcODg44OzuTnJwMwHPPPceAAQPYs2cPXbt2pV+/fnTo0OGWPqsQtZkkaSFqIQcHh2tuP1cWOzu7cpWzsrIq9V6j0aDX6wHo0aMHZ8+eZcWKFaxZs4bOnTszZswYZs6cWenxClGTSZu0EHeg7du3X/O+adOmADRt2pR9+/aRk5Nj3L5lyxa0Wi1NmjTBycmJ+vXrs27dutuKoW7dugwbNozvvvuOWbNmMX/+/Ns6nhC1kdSkhaiFCgoKSExMLLXO0tLS2Dnrp59+IiIigo4dO7Jo0SJ27tzJ//73PwCGDh3K66+/zrBhw5g2bRoXL17k+eef5/HHH8fLywuAadOm8eyzz+Lp6UmPHj3Iyspiy5YtPP/88+WKb+rUqbRp04bQ0FAKCgpYvny58UuCEKKEJGkhaqFVq1bh4+NTal2TJk04evQoYOh5vXjxYkaPHo2Pjw8//PADzZo1A8De3p7Vq1czfvx42rZti729PQMGDODDDz80HmvYsGHk5+fz0UcfMWnSJOrUqcPAgQPLHZ+1tTVTpkzhzJkz2NnZ0alTJxYvXlwJn1yI2kWjlFKmDkIIUX00Gg1Lly6lX79+pg5FCHET0iYthBBCmClJ0kIIIYSZkjZpIe4w0sIlRM0hNWkhhBDCTEmSFkIIIcyUJGkhhBDCTEmSFkIIIcyUJGkhhBDCTEmSFkIIIcyUJGkhhBDCTEmSFkIIIcyUJGkhhBDCTP0/mCKCp9mQ4bMAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def user_input(context):\n",
        "  generate_and_print_sample(model, tokenizer, device, context)"
      ],
      "metadata": {
        "id": "MpbAVLhlQLA5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = input(\"please enter starting context: \")\n",
        "user_input(context)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfMkgLV2E6WQ",
        "outputId": "6fcbe058-9868-453b-feba-b528520b545b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "please enter starting context: Hello I am Prakhar \n",
            "Hello I am Prakhar                                                   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")"
      ],
      "metadata": {
        "id": "LbsrUSI0E9RO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.load_state_dict(torch.load(\"model.pth\", map_location=device, weights_only=True))\n",
        "model.eval();"
      ],
      "metadata": {
        "id": "fzGyKRRFFEcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\n",
        "    \"model_state_dict\": model.state_dict(),\n",
        "    \"optimizer_state_dict\": optimizer.state_dict(),\n",
        "    },\n",
        "    \"model_and_optimizer.pth\"\n",
        ")"
      ],
      "metadata": {
        "id": "2hOjj3-vFHXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"model_and_optimizer.pth\", weights_only=True)\n",
        "\n",
        "model = GPTModel(GPT_CONFIG_124M)\n",
        "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
        "\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005, weight_decay=0.1)\n",
        "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
        "model.train();"
      ],
      "metadata": {
        "id": "Fej1UpMOFJqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XU1c-XTZFY3W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}